{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bca2f-8965-48ea-a92c-ce9fa9a872c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# /root/autodl-tmp/DeepFRI/03_run_galaxy/002_prepare_npz.ipynb\n",
    "\"\"\"\n",
    "Jupyter-ready: build DeepFRI NPZ from PDB/mmCIF (with .gz)\n",
    "- 输入目录: IN_DIR\n",
    "- 输出目录: OUT_DIR\n",
    "- 只保存接触图(contact)可省大量空间\n",
    "- 已存在的 npz 会跳过，支持断点续跑\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, gzip, json, time, shutil\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "\n",
    "# ===================== 配置区（按需修改） =====================\n",
    "# IN_DIR  = Path(\"/root/autodl-tmp/DeepFRI/03_run_galaxy/02_pdb_over70\")       # 你的PDB源目录\n",
    "IN_DIR  = Path(\"/root/autodl-tmp/DeepFRI/03_run_galaxy/01_pdb_galaxy_4deepPF\")\n",
    "OUT_DIR = Path(\"/root/autodl-tmp/DeepFRI/03_run_galaxy/02_pdb_galaxy_npz_fix\")  # 输出NPZ目录\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "WORKERS        = min(48, max(1, cpu_count() - 1))  # 并行数，别太大\n",
    "CONTACT_CUTOFF = 8.0                               # 接触图阈值(Å)\n",
    "MODE           = \"contact\"                         # \"contact\"|\"dist\"|\"both\"\n",
    "DIST_DTYPE     = \"float32\"                         # \"float32\"|\"float16\"\n",
    "MIN_FREE_GB    = 10.0                              # 输出盘至少要有这么多GB，否则停\n",
    "\n",
    "# ===============================================================\n",
    "AA3_TO_1 = {\n",
    "    'ALA':'A','ARG':'R','ASN':'N','ASP':'D','CYS':'C','GLU':'E','GLN':'Q','GLY':'G',\n",
    "    'HIS':'H','ILE':'I','LEU':'L','LYS':'K','MET':'M','PHE':'F','PRO':'P','SER':'S',\n",
    "    'THR':'T','TRP':'W','TYR':'Y','VAL':'V'\n",
    "}\n",
    "SUFFIXES = {\".pdb\", \".cif\", \".pdb.gz\", \".cif.gz\"}\n",
    "\n",
    "# 尝试选择解析后端\n",
    "try:\n",
    "    import gemmi\n",
    "    BACKEND = \"gemmi\"\n",
    "except Exception:\n",
    "    try:\n",
    "        from Bio.PDB import MMCIFParser, PDBParser, is_aa\n",
    "        BACKEND = \"biopython\"\n",
    "    except Exception:\n",
    "        BACKEND = None\n",
    "\n",
    "# ===================== 工具函数 =====================\n",
    "def norm_acc_from_filename(p: Path) -> str:\n",
    "    \"\"\"根据文件名生成ACC，去扩展名，去 __AF/__1ABC_A 这类后缀\"\"\"\n",
    "    stem = p.name\n",
    "    if stem.endswith(\".gz\"):\n",
    "        stem = stem[:-3]\n",
    "    for suf in (\".pdb\", \".cif\"):\n",
    "        if stem.endswith(suf):\n",
    "            stem = stem[:-len(suf)]\n",
    "            break\n",
    "    if \"__\" in stem:\n",
    "        stem = stem.split(\"__\")[0]\n",
    "    return stem\n",
    "\n",
    "def read_text_auto(p: Path) -> str:\n",
    "    \"\"\"自动识别.gz文本读取\"\"\"\n",
    "    if str(p).endswith(\".gz\"):\n",
    "        with gzip.open(p, \"rt\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        return p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def parse_with_gemmi(p: Path):\n",
    "    \"\"\"用gemmi解析，取最长的标准氨基酸链，返回 (chain, seq, coords(N,3), res_ids)\"\"\"\n",
    "    doc = gemmi.read_structure(str(p))\n",
    "    best = None\n",
    "    for model in doc:\n",
    "        for chain in model:\n",
    "            seq, coords, res_ids = [], [], []\n",
    "            for res in chain:\n",
    "                if not res.is_polymer():\n",
    "                    continue\n",
    "                name3 = res.name.upper().strip()\n",
    "                if name3 not in AA3_TO_1:\n",
    "                    continue\n",
    "                ca = res.find_atom(\"CA\", altloc='?')\n",
    "                if ca is None:\n",
    "                    continue\n",
    "                seq.append(AA3_TO_1[name3])\n",
    "                pos = ca.pos\n",
    "                coords.append([pos.x, pos.y, pos.z])\n",
    "                rid = f\"{chain.name}:{res.seqid.num}:{res.seqid.icode or ''}\"\n",
    "                res_ids.append(rid)\n",
    "            if seq:\n",
    "                cand = (chain.name, \"\".join(seq), np.asarray(coords, dtype=np.float32), res_ids)\n",
    "                if best is None or len(cand[1]) > len(best[1]):\n",
    "                    best = cand\n",
    "    return best\n",
    "\n",
    "def parse_with_biopython(p: Path):\n",
    "    \"\"\"biopython作为后备解析器\"\"\"\n",
    "    from Bio.PDB import MMCIFParser, PDBParser, is_aa\n",
    "    if str(p).endswith(\".cif\") or str(p).endswith(\".cif.gz\"):\n",
    "        parser = MMCIFParser(QUIET=True)\n",
    "    else:\n",
    "        parser = PDBParser(QUIET=True)\n",
    "    if str(p).endswith(\".gz\"):\n",
    "        from io import StringIO\n",
    "        txt = read_text_auto(p)\n",
    "        handle = StringIO(txt)\n",
    "        structure = parser.get_structure(\"S\", handle)\n",
    "    else:\n",
    "        structure = parser.get_structure(\"S\", str(p))\n",
    "    best = None\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            seq, coords, res_ids = [], [], []\n",
    "            for res in chain:\n",
    "                if not is_aa(res, standard=True):\n",
    "                    continue\n",
    "                ca = res[\"CA\"] if \"CA\" in res else None\n",
    "                if ca is None:\n",
    "                    continue\n",
    "                name3 = res.get_resname().upper().strip()\n",
    "                if name3 not in AA3_TO_1:\n",
    "                    continue\n",
    "                seq.append(AA3_TO_1[name3])\n",
    "                c = ca.get_coord()\n",
    "                coords.append([float(c[0]), float(c[1]), float(c[2])])\n",
    "                icode = res.id[2] if len(res.id) > 2 else \"\"\n",
    "                resnum = res.id[1]\n",
    "                rid = f\"{chain.id}:{resnum}:{icode or ''}\"\n",
    "                res_ids.append(rid)\n",
    "            if seq:\n",
    "                cand = (chain.id, \"\".join(seq), np.asarray(coords, dtype=np.float32), res_ids)\n",
    "                if best is None or len(cand[1]) > len(best[1]):\n",
    "                    best = cand\n",
    "    return best\n",
    "\n",
    "def coords_to_dist_and_contacts(coords: np.ndarray, cutoff: float, dist_dtype: str):\n",
    "    \"\"\"由Cα坐标得到距离矩阵和接触图\"\"\"\n",
    "    if coords.shape[0] == 0:\n",
    "        return None, None\n",
    "    x = coords.astype(np.float32)\n",
    "    xx = np.sum(x*x, axis=1, keepdims=True)\n",
    "    dist2 = xx + xx.T - 2.0 * (x @ x.T)\n",
    "    np.maximum(dist2, 0.0, out=dist2)\n",
    "    dist = np.sqrt(dist2, dtype=np.float32)\n",
    "    np.fill_diagonal(dist, 0.0)\n",
    "    contact_map = (dist <= cutoff).astype(np.uint8)\n",
    "    np.fill_diagonal(contact_map, 0)\n",
    "    if dist_dtype == \"float16\":\n",
    "        dist = dist.astype(np.float16)\n",
    "    return dist, contact_map\n",
    "\n",
    "def disk_free_gb(path: Path) -> float:\n",
    "    \"\"\"返回path所在分区的可用GB\"\"\"\n",
    "    usage = shutil.disk_usage(path)\n",
    "    return usage.free / (1024**3)\n",
    "\n",
    "def find_all_inputs(root: Path):\n",
    "    files = []\n",
    "    for suf in SUFFIXES:\n",
    "        files.extend(root.rglob(f\"*{suf}\"))\n",
    "    return sorted([p for p in files if p.is_file() and not p.name.startswith(\".\")])\n",
    "\n",
    "# 为了在Jupyter里也能并行，这里用全局变量注入\n",
    "GLOBAL_CFG = {}\n",
    "def init_worker(cfg):\n",
    "    GLOBAL_CFG.update(cfg)\n",
    "\n",
    "def process_one(p: Path):\n",
    "    out_dir   = GLOBAL_CFG[\"out_dir\"]\n",
    "    cutoff    = GLOBAL_CFG[\"cutoff\"]\n",
    "    mode      = GLOBAL_CFG[\"mode\"]\n",
    "    dist_dtype= GLOBAL_CFG[\"dist_dtype\"]\n",
    "    backend   = GLOBAL_CFG[\"backend\"]\n",
    "    min_free  = GLOBAL_CFG[\"min_free_gb\"]\n",
    "\n",
    "    try:\n",
    "        # 磁盘不足直接停止\n",
    "        if disk_free_gb(out_dir) < min_free:\n",
    "            return {\"acc\": None, \"npz_path\": None, \"n_res\": 0, \"ok\": False, \"msg\": \"low_disk_stop\"}\n",
    "\n",
    "        acc = norm_acc_from_filename(p)\n",
    "        out_npz = out_dir / f\"{acc}.npz\"\n",
    "        if out_npz.exists():\n",
    "            return {\"acc\": acc, \"npz_path\": str(out_npz.resolve()), \"n_res\": -1, \"ok\": True, \"msg\": \"exists_skip\"}\n",
    "\n",
    "        if backend == \"gemmi\":\n",
    "            parsed = parse_with_gemmi(p)\n",
    "        else:\n",
    "            parsed = parse_with_biopython(p)\n",
    "\n",
    "        if parsed is None:\n",
    "            return {\"acc\": acc, \"npz_path\": None, \"n_res\": 0, \"ok\": False, \"msg\": \"no_valid_chain\"}\n",
    "\n",
    "        chain_id, seq, coords, res_ids = parsed\n",
    "        if len(seq) < 2:\n",
    "            return {\"acc\": acc, \"npz_path\": None, \"n_res\": len(seq), \"ok\": False, \"msg\": \"too_short\"}\n",
    "\n",
    "        dist, contact_map = coords_to_dist_and_contacts(coords, cutoff, dist_dtype)\n",
    "\n",
    "        arrays = {\n",
    "            \"seq\": np.array(seq),\n",
    "            \"res_ids\": np.array(res_ids, dtype=object),\n",
    "            \"chain_id\": np.array(chain_id),\n",
    "        }\n",
    "        if mode in (\"dist\",\"both\"):\n",
    "            arrays[\"dist\"] = dist\n",
    "        if mode in (\"contact\",\"both\"):\n",
    "            arrays[\"contact_map\"] = contact_map\n",
    "\n",
    "        tmp_npz = out_npz.with_suffix(\".npz.tmp\")\n",
    "        np.savez_compressed(tmp_npz, **arrays)\n",
    "        os.replace(tmp_npz, out_npz)\n",
    "\n",
    "        return {\"acc\": acc, \"npz_path\": str(out_npz.resolve()), \"n_res\": len(seq), \"ok\": True, \"msg\": \"ok\"}\n",
    "\n",
    "    except OSError as e:\n",
    "        if \"No space left on device\" in str(e):\n",
    "            return {\"acc\": None, \"npz_path\": None, \"n_res\": 0, \"ok\": False, \"msg\": \"enospace\"}\n",
    "        return {\"acc\": None, \"npz_path\": None, \"n_res\": 0, \"ok\": False, \"msg\": f\"oserror:{e}\"}\n",
    "    except Exception as e:\n",
    "        return {\"acc\": None, \"npz_path\": None, \"n_res\": 0, \"ok\": False, \"msg\": f\"error:{e}\"}\n",
    "\n",
    "# ===================== 主运行 =====================\n",
    "if BACKEND is None:\n",
    "    print(\"[ERROR] gemmi/biopython 都不可用，请先安装其一\")\n",
    "else:\n",
    "    files = find_all_inputs(IN_DIR)\n",
    "    print(f\"[Config] BACKEND={BACKEND}\")\n",
    "    print(f\"[Config] IN_DIR={IN_DIR}\")\n",
    "    print(f\"[Config] OUT_DIR={OUT_DIR}\")\n",
    "    print(f\"[Scan] found candidate structures: {len(files)}\")\n",
    "    print(f\"[Parallel] workers={WORKERS}, mode={MODE}, dist_dtype={DIST_DTYPE}, min_free_gb={MIN_FREE_GB}\")\n",
    "\n",
    "    cfg = {\n",
    "        \"out_dir\": OUT_DIR,\n",
    "        \"cutoff\": CONTACT_CUTOFF,\n",
    "        \"mode\": MODE,\n",
    "        \"dist_dtype\": DIST_DTYPE,\n",
    "        \"backend\": BACKEND,\n",
    "        \"min_free_gb\": MIN_FREE_GB,\n",
    "    }\n",
    "\n",
    "    t0 = time.time()\n",
    "    records = []\n",
    "    stop = False\n",
    "\n",
    "    with Pool(processes=WORKERS, initializer=init_worker, initargs=(cfg,)) as pool:\n",
    "        for i, rec in enumerate(pool.imap_unordered(process_one, files, chunksize=16), 1):\n",
    "            records.append(rec)\n",
    "            if rec.get(\"msg\") in (\"low_disk_stop\", \"enospace\"):\n",
    "                stop = True\n",
    "                break\n",
    "            if i % 200 == 0:\n",
    "                ok_new = sum(1 for r in records if r.get(\"ok\") and r.get(\"msg\") == \"ok\")\n",
    "                exist  = sum(1 for r in records if r.get(\"ok\") and r.get(\"msg\") == \"exists_skip\")\n",
    "                fail   = sum(1 for r in records if not r.get(\"ok\"))\n",
    "                print(f\"[Progress] done={i} | ok_new={ok_new} | exists={exist} | fail={fail}\")\n",
    "        if stop:\n",
    "            pool.terminate()\n",
    "        pool.join()\n",
    "\n",
    "    ok_new   = [r for r in records if r.get(\"ok\") and r.get(\"msg\") == \"ok\"]\n",
    "    ok_exist = [r for r in records if r.get(\"ok\") and r.get(\"msg\") == \"exists_skip\"]\n",
    "    fail     = [r for r in records if not r.get(\"ok\")]\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    # 写结构映射\n",
    "    map_tsv = OUT_DIR / \"structure_map_all.tsv\"\n",
    "    with open(map_tsv, \"w\", encoding=\"utf-8\") as fo:\n",
    "        fo.write(\"acc\\tnpz_path\\n\")\n",
    "        for r in ok_new + ok_exist:\n",
    "            if r.get(\"acc\") and r.get(\"npz_path\"):\n",
    "                fo.write(f\"{r['acc']}\\t{r['npz_path']}\\n\")\n",
    "\n",
    "    # 写报告\n",
    "    rep_json = OUT_DIR / \"npz_build_report.json\"\n",
    "    report = {\n",
    "        \"backend\": BACKEND,\n",
    "        \"in_dir\": str(IN_DIR.resolve()),\n",
    "        \"out_dir\": str(OUT_DIR.resolve()),\n",
    "        \"mode\": MODE,\n",
    "        \"dist_dtype\": DIST_DTYPE,\n",
    "        \"contact_cutoff_A\": CONTACT_CUTOFF,\n",
    "        \"n_files\": len(files),\n",
    "        \"n_ok_new\": len(ok_new),\n",
    "        \"n_ok_exists\": len(ok_exist),\n",
    "        \"n_fail\": len(fail),\n",
    "        \"time_sec\": round(dt, 2),\n",
    "        \"stop_due_to_low_disk\": stop,\n",
    "        \"fail_examples\": fail[:10],\n",
    "    }\n",
    "    with open(rep_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"[Done] new={len(ok_new)} | exists={len(ok_exist)} | fail={len(fail)} | elapsed={round(dt,1)}s\")\n",
    "    if stop:\n",
    "        print(\"[HINT] 触发低磁盘保护：清理空间后重新运行此cell即可，已完成的npz会自动跳过。\")\n",
    "    print(f\"[Saved] map -> {map_tsv}\")\n",
    "    print(f\"[Saved] report -> {rep_json}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
